# Personalized Learning Roadmap Generator

A CLI-based system that generates personalized learning roadmaps by combining AI conversation, preference analysis, and adaptive roadmap generation.

## ğŸ¯ Overview

This project orchestrates a complete personalized learning experience:

1. **Role Selection** - User selects their target role (AI/Data Scientist, Full Stack Developer, etc.)
2. **Preset Roadmap Display** - Shows the standard learning path for that role
3. **AI Conversation** - Gemini LLM interviews the user about skills, experience, and goals
4. **Personalization** - Analyzes user profile and adjusts topic priorities, hours, and recommendations
5. **Roadmap Generation** - LLM generates a customized roadmap matching user preferences
6. **Output** - Displays and saves the personalized roadmap

## ğŸ“ Project Structure

```
4-2-26/
â”œâ”€â”€ main.py                      # Main orchestrator (entry point)
â”œâ”€â”€ llm/                         # Conversation engine
â”‚   â”œâ”€â”€ conversation_engine.py   # Manages user conversation
â”‚   â”œâ”€â”€ gemini_client.py         # Gemini API wrapper
â”‚   â”œâ”€â”€ role_guides.py           # Role definitions
â”‚   â”œâ”€â”€ system_prompt.py         # LLM system prompt
â”‚   â””â”€â”€ user_profile.py          # User profile management
â”œâ”€â”€ personalizer/                # Roadmap personalization
â”‚   â”œâ”€â”€ service.py               # Main personalization service
â”‚   â”œâ”€â”€ loader.py                # Load semantic roadmaps
â”‚   â”œâ”€â”€ llm.py                   # LLM interface (mock)
â”‚   â”œâ”€â”€ transform.py             # Apply personalization
â”‚   â”œâ”€â”€ prompt.py                # Personalization prompts
â”‚   â””â”€â”€ schemas.py               # Data validation
â”œâ”€â”€ roadmap_updater/             # NEW: Roadmap generation
â”‚   â”œâ”€â”€ updater.py               # Main roadmap updater
â”‚   â””â”€â”€ gemini_client.py         # Gemini API client
â”œâ”€â”€ fake frontend/               # Preset roadmaps (text format)
â”‚   â”œâ”€â”€ ai-ds                    # AI & Data Scientist roadmap
â”‚   â”œâ”€â”€ fs                       # Full Stack Developer roadmap
â”‚   â”œâ”€â”€ ml                       # Machine Learning Engineer roadmap
â”‚   â”œâ”€â”€ gd                       # Game Developer roadmap
â”‚   â””â”€â”€ sa                       # Software Architect roadmap
â”œâ”€â”€ conversion/                  # Pipeline for semantic data
â”œâ”€â”€ data/                        # Source roadmap data
â””â”€â”€ output/                      # Generated personalized outputs
    â”œâ”€â”€ {role}_profile.json      # User profile
    â”œâ”€â”€ {role}_personalized.json # Personalized semantic data
    â””â”€â”€ {role}_roadmap.txt       # Final personalized roadmap
```

## ğŸš€ Installation

1. **Clone the repository**
   ```bash
   cd C:\Users\Subbu\Desktop\Projects\4-2-26
   ```

2. **Install dependencies**
   ```bash
   pip install google-generativeai python-dotenv
   ```

3. **Set up environment variables**
   
   Create a `.env` file in the project root:
   ```
   GEMINI_API_KEY=your_gemini_api_key_here
   ```

## ğŸ® Usage

Run the main orchestrator:

```bash
python main.py
```

### Interactive Flow

1. **Select Role** - Choose from 5 available roles (1-5)

2. **View Preset Roadmap** - See the standard learning path
   - Press Enter to continue

3. **Conversation** - Answer questions about your background
   - The AI will ask about your skills, experience, and goals
   - Type your answers naturally
   - Type `done` when finished

4. **Personalization** - System analyzes your profile
   - Automatically adjusts priorities and hours

5. **View Personalized Roadmap** - See your custom learning path
   - Tailored to your experience and goals
   - Press Enter to continue

6. **Results Saved** - Check the `output/` folder for:
   - `{role}_profile.json` - Your user profile
   - `{role}_personalized.json` - Personalized data
   - `{role}_roadmap.txt` - Your custom roadmap

## ğŸ”§ Modules

### 1. LLM Module (`llm/`)
- **Purpose**: Conversational AI to extract user information
- **LLM**: Gemini 2.5 Flash
- **Key Files**:
  - `conversation_engine.py` - Orchestrates conversation flow
  - `gemini_client.py` - API wrapper for Gemini
  - `user_profile.py` - Stores and manages user data

### 2. Personalizer Module (`personalizer/`)
- **Purpose**: Analyze user profile and update roadmap semantics
- **Key Files**:
  - `service.py` - Main personalization pipeline
  - `transform.py` - Apply priority/hour adjustments
  - `loader.py` - Load semantic roadmap data

### 3. Roadmap Updater Module (`roadmap_updater/`) âœ¨ NEW
- **Purpose**: Generate updated roadmap text using LLM
- **LLM**: Gemini 2.5 Flash (same as conversation)
- **Key Files**:
  - `updater.py` - Main roadmap generation logic
  - `gemini_client.py` - Gemini API client
- **Inputs**:
  - Preset roadmap text
  - Personalized semantic data (priorities, hours)
  - User profile (skills, goals, experience)
- **Output**:
  - Updated roadmap in same tree format as preset

### 4. Main Orchestrator (`main.py`)
- **Purpose**: Coordinate all modules in sequence
- **Flow**: Selection â†’ Display â†’ Conversation â†’ Personalization â†’ Generation â†’ Display

## ğŸ“Š Data Flow

```
User Input
    â†“
Role Selection
    â†“
Preset Roadmap (fake frontend/) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                                     â”‚
LLM Conversation (llm/)                   â”‚
    â†“                                     â”‚
User Profile                              â”‚
    â†“                                     â†“
Personalizer (personalizer/)         Roadmap Updater
    â†“                                (roadmap_updater/)
Personalized Semantics                    â”‚
    â†“                                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
          Updated Roadmap Text
                   â†“
            Display + Save
```

## ğŸ§ª Testing

Test individual modules:

```bash
# Test LLM conversation
cd llm
python test_gemini.py

# Test personalizer
cd personalizer
python test_run.py

# Test end-to-end
python main.py
```

## ğŸ“ Configuration

### Available Roles

- `ai_data_scientist` - AI & Data Scientist
- `full_stack` - Full Stack Developer
- `machine_learning` - Machine Learning Engineer
- `game_developer` - Game Developer
- `software_architect` - Software Architect

### Customization

- **Add new roles**: 
  1. Add roadmap text to `fake frontend/`
  2. Update `ROLE_GUIDES` in `llm/role_guides.py`
  3. Add mapping in `main.py` `PRESET_ROADMAPS`

- **Adjust conversation length**: 
  - Modify `max_turns` in `main.py` `run_conversation()`

- **Change LLM model**:
  - Update `model="gemini-2.5-flash"` in Gemini client files

## ğŸ” Environment Variables

Required in `.env`:
- `GEMINI_API_KEY` - Your Google Gemini API key

## ğŸ“¦ Dependencies

- `google-generativeai` - Gemini API client
- `python-dotenv` - Environment variable management

## ğŸ¤ Contributing

The project follows a modular architecture:
- Each module is independent and testable
- Use the same LLM client pattern for consistency
- Follow the orchestration pattern in `main.py`

## ğŸ“„ License

MIT License

## ğŸ‰ Features

âœ… Interactive CLI interface  
âœ… AI-powered conversation  
âœ… Personalized learning priorities  
âœ… Adaptive roadmap generation  
âœ… Multiple role support  
âœ… Persistent result storage  
âœ… Modular architecture  

## ğŸ› Troubleshooting

**ModuleNotFoundError**:
- Ensure you're running from project root
- Check Python path includes all module folders

**API Key Error**:
- Verify `.env` file exists with `GEMINI_API_KEY`
- Check API key is valid and active

**Conversation doesn't start**:
- Type `done` to skip if needed
- Press Ctrl+C to interrupt gracefully

## ğŸ“ Support

For issues or questions, check:
1. Terminal output for error messages
2. Generated `output/` folder for results
3. Module test scripts for debugging
